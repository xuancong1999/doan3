{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as  np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Rescaling\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_minAreaRect(rect, box, gray):\n",
    "    mult = 1 \n",
    "    W = rect[1][0]\n",
    "    H = rect[1][1]\n",
    "\n",
    "    Xs = [i[0] for i in box]\n",
    "    Ys = [i[1] for i in box]\n",
    "    x1 = min(Xs)\n",
    "    x2 = max(Xs)\n",
    "    y1 = min(Ys)\n",
    "    y2 = max(Ys)\n",
    "\n",
    "    rotated = False\n",
    "    angle = rect[2]\n",
    "\n",
    "    if angle < -45:\n",
    "        angle+=90\n",
    "        rotated = True\n",
    "\n",
    "    center = (int((x1+x2)/2), int((y1+y2)/2))\n",
    "    size = (int(mult*(x2-x1)),int(mult*(y2-y1)))\n",
    "\n",
    "    M = cv2.getRotationMatrix2D((size[0]/2, size[1]/2), angle, 1.0)\n",
    "\n",
    "    cropped = cv2.getRectSubPix(gray, size, center)    \n",
    "    cropped = cv2.warpAffine(cropped, M, size)\n",
    "\n",
    "    croppedW = W if not rotated else H \n",
    "    croppedH = H if not rotated else W\n",
    "\n",
    "    croppedRotated = cv2.getRectSubPix(cropped, (int(croppedW*mult), int(croppedH*mult)), (size[0]/2, size[1]/2))\n",
    "    \n",
    "    return croppedRotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (64, 64, 3)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Rescaling((1.0 / 255), input_shape=(64, 64, 3)))\n",
    "model.add(Conv2D(16, (3,3), activation=\"relu\", padding=\"same\", kernel_initializer='he_uniform', name='block1'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), name='block1_maxpool'))\n",
    "\n",
    "model.add(Conv2D(32, (3,3), activation=\"relu\", padding=\"same\", kernel_initializer='he_uniform', name='block2'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), name='block2_maxpool'))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation=\"relu\", padding=\"same\", kernel_initializer='he_uniform', name='block3'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), name='block3_maxpool'))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " block1 (Conv2D)             (None, 64, 64, 16)        448       \n",
      "                                                                 \n",
      " block1_maxpool (MaxPooling2  (None, 32, 32, 16)       0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " block2 (Conv2D)             (None, 32, 32, 32)        4640      \n",
      "                                                                 \n",
      " block2_maxpool (MaxPooling2  (None, 16, 16, 32)       0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " block3 (Conv2D)             (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " block3_maxpool (MaxPooling2  (None, 8, 8, 64)         0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               524416    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                4128      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 552,161\n",
      "Trainable params: 552,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"model_vgg16.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.7413183e-06]]\n"
     ]
    }
   ],
   "source": [
    "img_crop=cv2.imread(\"91.jpg\",1)\n",
    "img_crop = cv2.resize(img_crop, (64,64), interpolation = cv2.INTER_AREA)\n",
    "img_crop = img_to_array(img_crop)\n",
    "img_crop = img_crop.reshape((1, img_crop.shape[0], img_crop.shape[1], img_crop.shape[2]))\n",
    "Y_box_pred = model.predict(img_crop)\n",
    "print(Y_box_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path='test2.mp4'\n",
    "cap=cv2.VideoCapture(video_path)\n",
    "backSub=cv2.createBackgroundSubtractorMOG2()\n",
    "if(cap.isOpened()==False):\n",
    "    print(\"Khong mo duoc video\")\n",
    "while (cap.isOpened()):\n",
    "    ret, frame=cap.read()\n",
    "    if ret==True:\n",
    "        #Thuat toan tru nen\n",
    "        fgMask=backSub.apply(frame)\n",
    "        fgMask=cv2.cvtColor(fgMask, 0) \n",
    "        #Dung bo loc ma tran 5*5\n",
    "        kernel = np.ones((7,7), np.uint8)\n",
    "        #Lay gia tri pixel nho nhat cua kernel lam manh net\n",
    "        fgMask=cv2.erode(fgMask,kernel,iterations=1)\n",
    "        #Lay gia tri pixel lon nhat cua kernel lam lien net\n",
    "        fgMask=cv2.dilate(fgMask,kernel,iterations=1)\n",
    "        \n",
    "        #tao them su lien net bang ham open\n",
    "        fgMask = cv2.morphologyEx(fgMask, cv2.MORPH_CLOSE, kernel,iterations=1)\n",
    "        #lay nguong 120\n",
    "        _,fgMask = cv2.threshold(fgMask,120,255,cv2.THRESH_BINARY)\n",
    "        #phat hien canh bang candy\n",
    "        fgMask=cv2.Canny(fgMask, 20, 200)\n",
    "        contours,_ = cv2.findContours(fgMask,cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        for i in range(len(contours)):\n",
    "            rect = cv2.minAreaRect(contours[i])\n",
    "            if (rect[1][0]*rect[1][1]) < 1000:\n",
    "                continue\n",
    "            \n",
    "            box = cv2.boxPoints(rect)\n",
    "            box = np.int0(box)\n",
    "            \n",
    "            img_crop = crop_minAreaRect(rect, box, frame)       \n",
    "            img_crop = cv2.resize(img_crop, (64,64), interpolation = cv2.INTER_AREA)\n",
    "            img_crop = img_to_array(img_crop)\n",
    "            img_crop = img_crop.reshape((1, img_crop.shape[0], img_crop.shape[1], img_crop.shape[2]))\n",
    "            cv2.drawContours(frame,[box],0,(0,255,0),2)\n",
    "        \n",
    "        \n",
    "            Y_box_pred = model.predict(img_crop)\n",
    "            if Y_box_pred <= 0.5:\n",
    "                cv2.putText(frame, \"Person\", (box[2][0], box[2][1]),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "            if Y_box_pred > 0.5:\n",
    "                cv2.putText(frame, \"Non\", (box[2][0], box[2][1]),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
    "\n",
    "        cv2.imshow('Frame',frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()    \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "44cc4b658cce6dbe14b2eff7543081a38d0bc42638c284a7d6b8be046ce6997c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
