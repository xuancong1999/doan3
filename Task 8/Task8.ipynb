{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Ich8-M6mVqk0"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2334,"status":"ok","timestamp":1645991502245,"user":{"displayName":"Nam Nguyễn Văn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02607592436705515465"},"user_tz":-420},"id":"vhzMjvD8v-G-","outputId":"0357f17e-fd05-4adb-ceb2-91f4706241c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1645991502246,"user":{"displayName":"Nam Nguyễn Văn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02607592436705515465"},"user_tz":-420},"id":"Nn9HFpMUXgF4","outputId":"835d841d-a3e4-458a-a21a-a3662b45a780"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/doan\n"]}],"source":["cd /content/drive/'My Drive'/doan"]},{"cell_type":"markdown","metadata":{"id":"7W1vk1t2YDjp"},"source":["**IMPORT DATA**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4381,"status":"ok","timestamp":1645991506622,"user":{"displayName":"Nam Nguyễn Văn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02607592436705515465"},"user_tz":-420},"id":"v62bkp5cXw9h","outputId":"1e5a6ba5-f1c2-4874-eddc-49af2ec3f587"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 21758 files belonging to 2 classes.\n","Using 17407 files for training.\n","Found 21758 files belonging to 2 classes.\n","Using 4351 files for validation.\n"]}],"source":["image_size = (64, 64)\n","batch_size = 32\n","\n","train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","    \"Class_Human\",\n","    validation_split=0.2,\n","    subset=\"training\",\n","    seed=18,\n","    image_size=image_size,\n","    batch_size=batch_size,\n",")\n","val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","    \"Class_Human\",\n","    validation_split=0.2,\n","    subset=\"validation\",\n","    seed=18,\n","    image_size=image_size,\n","    batch_size=batch_size,\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kEOkwduC01QX"},"outputs":[],"source":["train_ds = train_ds.prefetch(buffer_size=32)\n","val_ds = val_ds.prefetch(buffer_size=32)"]},{"cell_type":"markdown","metadata":{"id":"a9GMrb4tM0Hl"},"source":["**TRAINNING**"]},{"cell_type":"markdown","metadata":{"id":"9vJMIf_GNO3Z"},"source":["Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ui_EI59yTEjW"},"outputs":[],"source":["import tensorflow as tf\n","import tensorflow.keras\n","from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten,Rescaling\n","from tensorflow.keras.layers import Conv2D\n","from tensorflow.keras.layers import MaxPooling2D\n","from keras.models import Sequential"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PyO2wDU6T3XL"},"outputs":[],"source":["from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger, TensorBoard"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OAWIG3TYPbNk"},"outputs":[],"source":["callbacks = [\n","          #Luu bo trong so weight    \n","          ModelCheckpoint(\"files/model.h5\"),\n","          #Theo doi loss function va giam LR\n","          #factor gia tri learning rate se giam \n","          #patience: sau so chu ky ma LR se giam\n","          ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3),\n","          #Truyen lai ket qua vao CSV\n","          CSVLogger(\"files/data.csv\"),\n","          TensorBoard(),\n","          #Theo doi loss function\n","          #patience: sau so chu ky neu khong cai thien thi dung\n","          #restore_best_weights: lua chon khoi phuc tu epoch co ket qua tot nhat\n","          EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sZOlaK8UMzfO"},"outputs":[],"source":["input_shape = (64, 64, 3)\n","\n","\n","model = Sequential()\n","model.add(Rescaling((1.0 / 255), input_shape=(64, 64, 3)))\n","model.add(Conv2D(16, (3,3), activation=\"relu\", padding=\"same\", kernel_initializer='he_uniform', name='block1'))\n","model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), name='block1_maxpool'))\n","\n","model.add(Conv2D(32, (3,3), activation=\"relu\", padding=\"same\", kernel_initializer='he_uniform', name='block2'))\n","model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), name='block2_maxpool'))\n","\n","model.add(Conv2D(64, (3,3), activation=\"relu\", padding=\"same\", kernel_initializer='he_uniform', name='block3'))\n","model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), name='block3_maxpool'))\n","\n","\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(32, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","def optimizer_init_fn(): \n","  learning_rate = 1e-4\n","  return tf.keras.optimizers.Adam(learning_rate) \n","\n","model.compile(optimizer=optimizer_init_fn(),\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])"]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WT-DClMltwGa","executionInfo":{"status":"ok","timestamp":1645991507072,"user_tz":-420,"elapsed":464,"user":{"displayName":"Nam Nguyễn Văn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02607592436705515465"}},"outputId":"8fbe8edb-4402-4bd8-d691-eddfb97ef1c4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," rescaling (Rescaling)       (None, 64, 64, 3)         0         \n","                                                                 \n"," block1 (Conv2D)             (None, 64, 64, 16)        448       \n","                                                                 \n"," block1_maxpool (MaxPooling2  (None, 32, 32, 16)       0         \n"," D)                                                              \n","                                                                 \n"," block2 (Conv2D)             (None, 32, 32, 32)        4640      \n","                                                                 \n"," block2_maxpool (MaxPooling2  (None, 16, 16, 32)       0         \n"," D)                                                              \n","                                                                 \n"," block3 (Conv2D)             (None, 16, 16, 64)        18496     \n","                                                                 \n"," block3_maxpool (MaxPooling2  (None, 8, 8, 64)         0         \n"," D)                                                              \n","                                                                 \n"," flatten (Flatten)           (None, 4096)              0         \n","                                                                 \n"," dense (Dense)               (None, 128)               524416    \n","                                                                 \n"," dense_1 (Dense)             (None, 32)                4128      \n","                                                                 \n"," dense_2 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 552,161\n","Trainable params: 552,161\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# Fit model (training)\n","history = model.fit(train_ds, steps_per_epoch=len(train_ds),\n","    validation_data=val_ds, validation_steps=len(val_ds), epochs=30, verbose=1,callbacks=callbacks)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h7NOT5LMtkoI","executionInfo":{"status":"ok","timestamp":1645993847549,"user_tz":-420,"elapsed":2340481,"user":{"displayName":"Nam Nguyễn Văn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02607592436705515465"}},"outputId":"08efb231-119d-44e8-a73b-5ec134ea93a3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","544/544 [==============================] - 1561s 3s/step - loss: 0.2715 - accuracy: 0.8903 - val_loss: 0.1399 - val_accuracy: 0.9483 - lr: 1.0000e-04\n","Epoch 2/30\n","544/544 [==============================] - 40s 74ms/step - loss: 0.1022 - accuracy: 0.9657 - val_loss: 0.0802 - val_accuracy: 0.9749 - lr: 1.0000e-04\n","Epoch 3/30\n","544/544 [==============================] - 41s 75ms/step - loss: 0.0656 - accuracy: 0.9789 - val_loss: 0.0600 - val_accuracy: 0.9793 - lr: 1.0000e-04\n","Epoch 4/30\n","544/544 [==============================] - 41s 74ms/step - loss: 0.0452 - accuracy: 0.9855 - val_loss: 0.0537 - val_accuracy: 0.9832 - lr: 1.0000e-04\n","Epoch 5/30\n","544/544 [==============================] - 40s 74ms/step - loss: 0.0358 - accuracy: 0.9883 - val_loss: 0.0493 - val_accuracy: 0.9848 - lr: 1.0000e-04\n","Epoch 6/30\n","544/544 [==============================] - 41s 75ms/step - loss: 0.0280 - accuracy: 0.9915 - val_loss: 0.0447 - val_accuracy: 0.9853 - lr: 1.0000e-04\n","Epoch 7/30\n","544/544 [==============================] - 41s 75ms/step - loss: 0.0221 - accuracy: 0.9929 - val_loss: 0.0427 - val_accuracy: 0.9867 - lr: 1.0000e-04\n","Epoch 8/30\n","544/544 [==============================] - 41s 74ms/step - loss: 0.0160 - accuracy: 0.9954 - val_loss: 0.0380 - val_accuracy: 0.9880 - lr: 1.0000e-04\n","Epoch 9/30\n","544/544 [==============================] - 41s 75ms/step - loss: 0.0120 - accuracy: 0.9966 - val_loss: 0.0347 - val_accuracy: 0.9901 - lr: 1.0000e-04\n","Epoch 10/30\n","544/544 [==============================] - 40s 73ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 0.0367 - val_accuracy: 0.9883 - lr: 1.0000e-04\n","Epoch 11/30\n","544/544 [==============================] - 41s 75ms/step - loss: 0.0101 - accuracy: 0.9971 - val_loss: 0.0331 - val_accuracy: 0.9899 - lr: 1.0000e-04\n","Epoch 12/30\n","544/544 [==============================] - 42s 77ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.0357 - val_accuracy: 0.9887 - lr: 1.0000e-04\n","Epoch 13/30\n","544/544 [==============================] - 43s 78ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.0372 - val_accuracy: 0.9899 - lr: 1.0000e-04\n","Epoch 14/30\n","544/544 [==============================] - 43s 78ms/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.0342 - val_accuracy: 0.9910 - lr: 1.0000e-04\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"name":"Task8.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP8SNmiQi5chBr+T4+Q7KmC"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}